{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre procesado y optención del vector para el algoritmo de aprendisaje\n",
    "*Se emplea el SEL de palabras teniendo en cuenta las emociones siguientes*\n",
    "\n",
    "    -Alegría\n",
    "    -Enojo\n",
    "    -Miedo\n",
    "    -Tristeza\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Importar las librerias necesarias**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xlrd\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import openpyxl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Leer datos de SEL**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_ = xlrd.open_workbook(\"constant_files/SEL.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Leer datos de la primera hoja del documento**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "emotions = file_.sheet_by_index(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Se crea una lista con las emociones que no son relevantes para nuestro algoritmo**\n",
    "\n",
    "*- Estas emociones serán omitidas de nuestro procesamiento*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "omit = ['Repulsión', 'Sorpresa']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Se crea un diccionario que contiene las emociones como llaves o keys y una lista de tuplas tipo (palabra, PFA)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "emotion_dic = {}\n",
    "for i in range(1, emotions.nrows):\n",
    "    fila = emotions.row(i)\n",
    "    if fila[3].value not in emotion_dic.keys() and fila[3].value not in omit:\n",
    "        emotion_dic[fila[3].value] = []\n",
    "\n",
    "for i in range(1, emotions.nrows):\n",
    "    fila = emotions.row(i)\n",
    "\n",
    "    if fila[3].value in omit:\n",
    "        pass\n",
    "    else:\n",
    "\n",
    "        if fila[1].value not in emotion_dic[fila[3].value]:\n",
    "            emotion_dic[fila[3].value].append((fila[1].value, fila[2].value))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Se crea una lista con los 4 archivos de entrenamiento que se corresponden con las 4 emociones dadas para el problema**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_files = [\"anger.txt\", \"fear.txt\", \"joy.txt\", \"sadness.txt\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Se leen cierta cantidad de lineas (*100*) de cada fichero y se crea una lista que contiene todos los comentarios sin procesar**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_commets = 100\n",
    "\n",
    "comments = []\n",
    "for file_selected in training_files:\n",
    "    entry_file = open(f\"entry_files/{file_selected}\")\n",
    "\n",
    "    # desecha la primera linea que no es útil\n",
    "    metadata = entry_file.readline()\n",
    "\n",
    "    # define la cantidad de comentarios de cada fichero\n",
    "    limit = num_commets\n",
    "\n",
    "    while limit > 0:\n",
    "        line = entry_file.readline()\n",
    "        # Desecha todo lo que no forma parte del comentario\n",
    "        comment = line.split(\"\\t\")[1]\n",
    "        if comment in comments:\n",
    "            pass\n",
    "        else:\n",
    "            comments.append(comment)\n",
    "            limit -= 1\n",
    "\n",
    "    entry_file.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Se tokenizan los comentarios y se eliminan los stop_words**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2684\n"
     ]
    }
   ],
   "source": [
    "tokenized_comments = []\n",
    "for comment in comments:\n",
    "    tokens = word_tokenize(comment)\n",
    "    words = [word.lower() for word in tokens if word.isalpha()]\n",
    "    stop_words = stopwords.words('spanish')\n",
    "    tokenized_comments.append([w for w in words if w not in stop_words])\n",
    "\n",
    "suma = 0\n",
    "for commet in tokenized_comments:\n",
    "    suma += len(commet)\n",
    "print(suma)\n",
    "# print(tokenized_comments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Se usa un metodo de reducción del umbral de palabras del SEL en este caso *Zimmermann_Zysno***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "T_en = 1\n",
    "T_e_complement = 1\n",
    "e_s = []\n",
    "for key in emotion_dic.keys():\n",
    "    suma = 0\n",
    "    e = 0\n",
    "    for pfa in emotion_dic[key]:\n",
    "        suma += pfa[1]\n",
    "\n",
    "    e = suma / len(emotion_dic[key])\n",
    "    e_complement = 1 - e\n",
    "\n",
    "    T_en *= e\n",
    "    T_e_complement *= e_complement\n",
    "\n",
    "ganma = T_en / (T_en + T_e_complement)\n",
    "\n",
    "mul1 = (T_en ** (1 - ganma))\n",
    "mul2 = (T_e_complement ** ganma)\n",
    "pfa_umbral = (T_en ** (1 - ganma)) * (1 - (T_e_complement ** ganma))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**De acuerdo al umbral calculado se descartan las palabras del SEL que están por debajo del umbral**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "emotion_dic_umbral = {}\n",
    "for key in emotion_dic.keys():\n",
    "    emotion_dic_umbral[key] = []\n",
    "    for pfa in emotion_dic[key]:\n",
    "        if pfa[1] >= pfa_umbral:\n",
    "            emotion_dic_umbral[key].append(pfa[0])\n",
    "\n",
    "# print(emotion_dic_umbral)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Se define la función que calcula la ocurrencia**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ocu(word, comments):\n",
    "    \"\"\"\n",
    "    Calcula la ocurrencia de una palabra en todos los\n",
    "    comentarios\n",
    "    \"\"\"\n",
    "    count = 0\n",
    "    for comment in comments:\n",
    "        if word in comment:\n",
    "            count += 1\n",
    "\n",
    "    return count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Se define la función que calcula la concurrencia**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concu(word1, word2, comments):\n",
    "    \"\"\"\n",
    "    Calcula la concurrencia de dos palabras en todos los\n",
    "    comentarios\n",
    "    \"\"\"\n",
    "    count = 0\n",
    "    for comment in comments:\n",
    "        if word1 in comment and word2 in comment:\n",
    "            count += 1\n",
    "\n",
    "    return count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Se unen todas las palabras del SEL y se almacenan en una lista solo las que tienen una ocurrencia mayor que 0**\n",
    "*Esta operación permite decantar palabras que nos hacen 0 la ecuación $concurrece(w, v)  /  ocurrence(w) * ocurrence(v)$*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_words = []\n",
    "for key in emotion_dic_umbral.keys():\n",
    "    all_words += emotion_dic_umbral[key]\n",
    "\n",
    "ocurrency_words = []\n",
    "for w in all_words:\n",
    "    if ocu(w, tokenized_comments) > 0:\n",
    "        ocurrency_words.append(w)\n",
    "\n",
    "# print(ocurrency_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Se calcula la ocurrencia de las palabras de los comentarios y se almacenan en el diccionario *words_ocu_dic*, se calcula la concurrencia con las palabras de *ocurrency_words* y se almacenan en el  diccionario *concur_dic***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_ocu_dic = {}\n",
    "concur_dic = {}\n",
    "for comment in tokenized_comments:\n",
    "    for w in comment:\n",
    "        if w not in words_ocu_dic.keys():\n",
    "            words_ocu_dic[w] = ocu(w, tokenized_comments)\n",
    "\n",
    "        for w2 in ocurrency_words:\n",
    "            key = f'{w}-{w2}'\n",
    "            if key not in concur_dic.keys():\n",
    "                concur_dic[key] = concu(w, w2, tokenized_comments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Se calcula la ocurrencia de las palabras de *ocurrency_words***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_words_ocu_dic = {}\n",
    "for comment in tokenized_comments:\n",
    "    for w in ocurrency_words:\n",
    "        if w not in f_words_ocu_dic.keys():\n",
    "            f_words_ocu_dic[w] = ocu(w, tokenized_comments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Se aplica la fórmula para calcular $O(wi, Ej)$ a todos los comentarios optieniendo el diccionario *average_word_emotion* que contiene como llave todos los comentarios, sus palabras y el valor de $O(wi, Ej)$ de cada una de ellas respecto a cada emoción**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_word_emotion = {}\n",
    "for comment in tokenized_comments:\n",
    "    original_comment = comments[tokenized_comments.index(comment)]\n",
    "    average_word_emotion[original_comment] = {}\n",
    "\n",
    "    for word in comment:\n",
    "        average_word_emotion[original_comment][word] = {}\n",
    "\n",
    "        for i in range(0, len(emotion_dic_umbral.keys())):\n",
    "            mod_E = len(emotion_dic[list(emotion_dic_umbral.keys())[i]])\n",
    "            emotion = list(emotion_dic_umbral.keys())[i]\n",
    "            emotion_words = emotion_dic_umbral[emotion]\n",
    "            word_ocurrence = words_ocu_dic[word]\n",
    "            sum_ = 0\n",
    "\n",
    "            for f_w in emotion_words:\n",
    "                try:\n",
    "                    sum_ += round((concur_dic[f'{word}-{f_w}'] /\n",
    "                        (f_words_ocu_dic[f_w] * words_ocu_dic[word])), 6)\n",
    "\n",
    "                except:\n",
    "                    sum_ += 0\n",
    "\n",
    "            average_word_emotion[original_comment][word][emotion] =\\\n",
    "                round((sum_ / mod_E), 6)\n",
    "\n",
    "# print(average_word_emotion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Se calcula el vecto realizando las siguientes operaciones:**\n",
    "1. Se extrae la emoción com mayor promedio de $O(wi, Ej)$\n",
    "2. Dada la emoción se añaden de manera exclusiva las palabras con $O(wi, Ej)$ > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1021\n"
     ]
    }
   ],
   "source": [
    "vector = {}\n",
    "for commnet in average_word_emotion.keys():\n",
    "    commnet_dic = {}\n",
    "    for words in average_word_emotion[commnet].keys():\n",
    "        word_emo = average_word_emotion[commnet][words]\n",
    "        for emotion in word_emo.keys():\n",
    "            o = word_emo[emotion]\n",
    "            if emotion not in commnet_dic.keys():\n",
    "                commnet_dic[emotion] = o\n",
    "            else:\n",
    "                commnet_dic[emotion] += o\n",
    "\n",
    "    max_prom = 0\n",
    "    max_emo = ''\n",
    "    module_o = len(average_word_emotion[commnet])\n",
    "    for emot in commnet_dic.keys():\n",
    "        prom = commnet_dic[emot] / module_o\n",
    "        if prom > max_prom:\n",
    "            max_emo = emot\n",
    "            max_prom = prom\n",
    "\n",
    "    for w in average_word_emotion[commnet].keys():\n",
    "        try:\n",
    "            emotion = average_word_emotion[commnet][w][max_emo]\n",
    "            word_O_tuple = (w, emotion)\n",
    "            if emotion > 0 and word_O_tuple not in vector:\n",
    "                vector[w] = emotion\n",
    "        except KeyError:\n",
    "            pass\n",
    "\n",
    "# print(vector)\n",
    "print(len(vector))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Se calcula una matriz para el aprendisaje usando el modelo booleano $TF-IDF$ y una con el valor $O(wi, Ej)$**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf = []\n",
    "O_w = []\n",
    "count = 1\n",
    "for comment in tokenized_comments:\n",
    "    fila = []\n",
    "    fila1 = []\n",
    "    for vector_word in vector.keys():\n",
    "        if vector_word in comment:\n",
    "            fila.append(1)\n",
    "            fila1.append(vector[vector_word])\n",
    "        else:\n",
    "            fila.append(0)\n",
    "            fila1.append(0)\n",
    "\n",
    "    if count <= num_commets:\n",
    "        fila.append('enfado')\n",
    "        fila1.append('enfado')\n",
    "    elif count > num_commets and count <= num_commets * 2:\n",
    "        fila.append('miedo')\n",
    "        fila1.append('miedo')\n",
    "    elif count > num_commets * 2 and count <= num_commets * 3:\n",
    "        fila.append('alegria')\n",
    "        fila1.append('alegria')\n",
    "    else:\n",
    "        fila.append('tristeza')\n",
    "        fila1.append('tristeza')\n",
    "\n",
    "    count += 1\n",
    "\n",
    "    tf_idf.append(fila)\n",
    "    O_w.append(fila1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Por último se guardan los vectores en documentos excel separados que utilizará nuestro modelo de aprendizaje**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "wb = openpyxl.Workbook()\n",
    "sheet = wb.active\n",
    "sheet.append(list(vector.keys()) + ['emoción'])\n",
    "for com in tf_idf:\n",
    "    sheet.append(com)\n",
    "wb.save('pre_pros_tf_idf.xlsx')\n",
    "\n",
    "wb = openpyxl.Workbook()\n",
    "sheet = wb.active\n",
    "sheet.append(list(vector.keys()) + ['emoción'])\n",
    "for com in O_w:\n",
    "    sheet.append(com)\n",
    "wb.save('pre_pros_O_w.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
